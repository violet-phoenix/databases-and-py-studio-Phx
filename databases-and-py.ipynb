{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "54326aff-51cd-4766-8046-828a92489c6d"
   },
   "source": [
    "# Studio: Working with Databases in Python\n",
    "\n",
    "For today's studio, we will be using the [TV Shows dataset](https://www.kaggle.com/ruchi798/tv-shows-on-netflix-prime-video-hulu-and-disney) from Kaggle. We have already downloaded the CSV for you.\n",
    "\n",
    "You will also be using the watchlist you just created to figure out which streaming services contain the shows that you want to watch next so you can decide which one is worth the money to you.\n",
    "\n",
    "As you complete the different tasks in the studio, you may choose between using Pandas or SQL. Remember that during the prep work, we learned that one is oftentimes more efficient at certain tasks than the other, so choose wisely!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "00bc62ef-6c46-40a2-bdad-a3250a003ce7"
   },
   "source": [
    "## My Watchlist\n",
    "\n",
    "If you would like, please use this space to make note of your watchlist by editing the text cell.\n",
    "\n",
    "Watchlist: \n",
    "Forever\n",
    "The Crown\n",
    "A Series of Unfortunate Events\n",
    "The Marvelous Mrs. Maisel\n",
    "Black Mirror\n",
    "Five Came Back\n",
    "Alias Grace\n",
    "The Handmaid's Tale\n",
    "Transparent\n",
    "Dear White People\n",
    "Fleabag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "040bdac5-f7fc-474f-b112-1d807249ad0a"
   },
   "source": [
    "## Database Setup\n",
    "\n",
    "To start with, import the necessary libraries and create a dataframe from the provided CSV. Print the info out for the dataframe. After that, you may drop the column called `Unnamed: 0` and rename any columns with spaces in the names or unusual characters such as `\"+\"`. Print out the info for the dataframe again to ensure that your changes were effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "azdata_cell_guid": "965f15d3-27b1-43ed-97e4-8c6fd482476c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5368 entries, 0 to 5367\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Unnamed: 0       5368 non-null   int64 \n",
      " 1   ID               5368 non-null   int64 \n",
      " 2   Title            5368 non-null   object\n",
      " 3   Year             5368 non-null   int64 \n",
      " 4   Age              3241 non-null   object\n",
      " 5   IMDb             4406 non-null   object\n",
      " 6   Rotten Tomatoes  5368 non-null   object\n",
      " 7   Netflix          5368 non-null   int64 \n",
      " 8   Hulu             5368 non-null   int64 \n",
      " 9   Prime Video      5368 non-null   int64 \n",
      " 10  Disney+          5368 non-null   int64 \n",
      " 11  Type             5368 non-null   int64 \n",
      "dtypes: int64(8), object(4)\n",
      "memory usage: 503.4+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5368 entries, 0 to 5367\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   ID               5368 non-null   int64 \n",
      " 1   Title            5368 non-null   object\n",
      " 2   Year             5368 non-null   int64 \n",
      " 3   Age              3241 non-null   object\n",
      " 4   IMDb             4406 non-null   object\n",
      " 5   Rotten_Tomatoes  5368 non-null   object\n",
      " 6   Netflix          5368 non-null   int64 \n",
      " 7   Hulu             5368 non-null   int64 \n",
      " 8   Prime            5368 non-null   int64 \n",
      " 9   Disney           5368 non-null   int64 \n",
      " 10  Type             5368 non-null   int64 \n",
      "dtypes: int64(7), object(4)\n",
      "memory usage: 461.4+ KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laure\\AppData\\Local\\Temp\\ipykernel_20308\\153543276.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  shows_df = shows_df.drop('Unnamed: 0', 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3 as sl\n",
    "\n",
    "shows_df = pd.read_csv('tv_shows.csv')\n",
    "print(shows_df.info())\n",
    "shows_df = shows_df.drop('Unnamed: 0', 1)\n",
    "shows_df = shows_df.rename(columns = {'Rotten Tomatoes':'Rotten_Tomatoes', 'Prime Video':'Prime', 'Disney+':'Disney'})\n",
    "print(shows_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "93875e01-f1ec-45ab-b8b3-c0fe09c89c41"
   },
   "source": [
    "With your dataframe at the ready, create a new database called `tv`. Add a new table to your database called `shows` using the data in the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "azdata_cell_guid": "cae4affc-d930-4649-9c39-551475a83b5b",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Table 'shows' already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20308\\858568382.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tv.db'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mshows_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'shows'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# also works: pd.read_sql_query(sql_query_string, connection name)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2949\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msql\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2951\u001b[1;33m         return sql.to_sql(\n\u001b[0m\u001b[0;32m   2952\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2953\u001b[0m             \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    696\u001b[0m         )\n\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 698\u001b[1;33m     return pandas_sql.to_sql(\n\u001b[0m\u001b[0;32m    699\u001b[0m         \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, **kwargs)\u001b[0m\n\u001b[0;32m   2190\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2191\u001b[0m         )\n\u001b[1;32m-> 2192\u001b[1;33m         \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2193\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    832\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"fail\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 834\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Table '{self.name}' already exists.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    835\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpd_sql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Table 'shows' already exists."
     ]
    }
   ],
   "source": [
    "con = sl.connect('tv.db')\n",
    "shows_df.to_sql('shows', con) # also works: pd.read_sql_query(sql_query_string, connection name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "4916f211-149f-467b-b5e4-22ad946b54f2"
   },
   "source": [
    "With your new table and database set up, print out the top 20 records in the `shows`Â table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "c6aa3980-3eef-4d7d-8f04-961508662147",
    "tags": []
   },
   "outputs": [],
   "source": [
    "shows_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "f158ccd2-c87a-4d2c-a947-0eadd0484a3e"
   },
   "source": [
    "Now add a table that includes an id number and the titles on your watchlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "f95defad-521b-4112-8435-08daaac80b80"
   },
   "outputs": [],
   "source": [
    "con.execute(\"\"\"\n",
    "        CREATE TABLE watchlist (\n",
    "            id INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT,\n",
    "            title TEXT\n",
    "        );\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sql = 'INSERT INTO watchlist (id, title) values(?, ?)'\n",
    "data = [\n",
    "        (1, 'Forever'),\n",
    "        (2, 'The Crown'),\n",
    "        (3, 'A Series of Unfortunate Events'),\n",
    "        (4, 'The Marvelous Mrs. Maisel'),\n",
    "        (5, 'Black Mirror'),\n",
    "        (6, 'Five Came Back'),\n",
    "        (7, 'Alias Grace'),\n",
    "        (8, '''The Handmaid's Tale'''),\n",
    "        (9, 'Transparent'),\n",
    "        (10, 'Dear White People'),\n",
    "        (11, 'Fleabag')\n",
    "    ]\n",
    "\n",
    "con.executemany(sql, data)\n",
    "\n",
    "data = con.execute(\"SELECT * FROM watchlist\")\n",
    "for row in data:\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "4716090d-63e3-4283-8245-934c4a28c750"
   },
   "source": [
    "## Working with the Data\n",
    "\n",
    "Using either Pandas or SQL, determine how many shows are on each streaming service and what the mean is for each streaming service. \n",
    "\n",
    "**Note**: You may notice that the mean represents the percentage of shows in the dataframe that are on each streaming service. Take a moment to think about why that is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "8e4f3757-474f-4e20-b861-db973437b541"
   },
   "outputs": [],
   "source": [
    "print(shows_df.describe())\n",
    "print(shows_df['Netflix'].value_counts())\n",
    "print(shows_df['Hulu'].value_counts())\n",
    "print(shows_df['Prime'].value_counts())\n",
    "print(shows_df['Disney'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "167cbd0d-ad9f-4f27-8066-e45dfdfaf421"
   },
   "source": [
    "Join your watchlist data with the shows data to determine which streaming services your watchlist shows are on and make a new table in your database using the joined data. Print out the data in your joined table to see what shows on your watchlist on in the original dataset. With the joined data, determine the percentage of your watchlist shows that are on each streaming service and how many of your watchlist shows are on each streaming service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "b871523e-a476-4f3a-a6ac-2e251f140e84"
   },
   "outputs": [],
   "source": [
    "streaming_df = pd.read_sql(\"\"\"\n",
    "     SELECT watchlist.title, shows.Netflix, shows.Hulu, shows.Prime, shows.Disney \n",
    "     FROM watchlist JOIN shows ON shows.Title == watchlist.title;\n",
    "     \"\"\", con)\n",
    "\n",
    "streaming_df.to_sql('watchlist_streaming', con)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            title  Netflix  Hulu  Prime  Disney\n",
      "0                         Forever        0     0      1       0\n",
      "1                       The Crown        1     0      0       0\n",
      "2  A Series of Unfortunate Events        1     0      0       0\n",
      "3       The Marvelous Mrs. Maisel        0     0      1       0\n",
      "4                    Black Mirror        1     0      0       0\n",
      "5                  Five Came Back        1     0      0       0\n",
      "6                     Alias Grace        1     0      0       0\n",
      "7             The Handmaid's Tale        0     1      0       0\n",
      "8                     Transparent        0     0      1       0\n",
      "9               Dear White People        1     1      0       0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11 entries, 0 to 10\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    11 non-null     object\n",
      " 1   Netflix  11 non-null     int64 \n",
      " 2   Hulu     11 non-null     int64 \n",
      " 3   Prime    11 non-null     int64 \n",
      " 4   Disney   11 non-null     int64 \n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 568.0+ bytes\n",
      "None\n",
      "         Netflix       Hulu      Prime  Disney\n",
      "count  11.000000  11.000000  11.000000    11.0\n",
      "mean    0.545455   0.181818   0.363636     0.0\n",
      "std     0.522233   0.404520   0.504525     0.0\n",
      "min     0.000000   0.000000   0.000000     0.0\n",
      "25%     0.000000   0.000000   0.000000     0.0\n",
      "50%     1.000000   0.000000   0.000000     0.0\n",
      "75%     1.000000   0.000000   1.000000     0.0\n",
      "max     1.000000   1.000000   1.000000     0.0\n",
      "1    6\n",
      "0    5\n",
      "Name: Netflix, dtype: int64\n",
      "0    9\n",
      "1    2\n",
      "Name: Hulu, dtype: int64\n",
      "0    7\n",
      "1    4\n",
      "Name: Prime, dtype: int64\n",
      "0    11\n",
      "Name: Disney, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(streaming_df.head(10))\n",
    "print(streaming_df.info())\n",
    "print(streaming_df.describe())\n",
    "\n",
    "print(streaming_df['Netflix'].value_counts())\n",
    "print(streaming_df['Hulu'].value_counts())\n",
    "print(streaming_df['Prime'].value_counts())\n",
    "print(streaming_df['Disney'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "909689e4-1aae-41e3-b1f8-158ebe5ec3ca"
   },
   "source": [
    "## Results\n",
    "\n",
    "Now that you have done your analysis, make note of the answers to the following questions by editing the text cell:\n",
    "\n",
    "1. Was every show on your watchlist in the Kaggle dataset? Do you have any ideas as to why a show might not have been present?\n",
    "No, since I generated my \"watchlist\" from a list of the supposed greatest streaming shows of all time. \"Fleabag\" was notably missing from my final analysis. Shows released in the last year or shows that required a \"sub\" subscription (such as AMC, a subscription WITHIN Amazon Prime) may not have been present in this dataset. Likewise, most streaming services offer licenses for a limited time and rotate titles into and out of their collections, so this dataset is limited to its most recent update.\n",
    "2. Did you include a show or shows in your watchlist that is exclusive to one of the platforms? How might that have impacted your analysis?\n",
    "Yes, all of these shows except Dear White People appear to be platform exclusives (e.g. only on 1 of the 4 platforms). I did not analyze the level of overlap between platforms, and it may be that one streaming service offers more overlapping titles of interest than it does originals/exclusives. If this is the case, it may be wiser to select a streaming service with more compelling originals than selecting a streaming service with mainly redundant titles that can be found on multiple services.\n",
    "2. Which streaming service(s) offered the most shows on your watchlist? Which streaming service(s) offered the least?\n",
    "Netflix offered 6 of the 11 shows I wanted to watch, while Disney+ offered 0.\n",
    "3. Based on the shows you want to watch and the results of your analysis, is there a streaming service you think would be a good fit for you?\n",
    "Clearly, Netflix would meet about half of my streaming 'needs,' if you can call them needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
